{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e11b64b8-e6b7-4f03-9dea-7c35b67c1e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "shakespeare_url = \"https://homl.info/shakespeare\" # shortcut URL\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c06e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66f0eff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  e t o a']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(\"hi\")\n",
    "tokenizer.sequences_to_texts([[1, 2, 3, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a976e929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ids = len(tokenizer.word_index)\n",
    "max_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "145a21c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = tokenizer.document_count\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f08e920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "678e59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33a3244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 150\n",
    "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c61bb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window:window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57d6eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10000)\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[1:]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1f59374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, GRU, LayerNormalization, Dense, Dropout, TimeDistributed\n",
    "import os\n",
    "\n",
    "def build_model(max_ids: int,\n",
    "                embedding_dim: int = 128,\n",
    "                gru_units: int = 256,\n",
    "                dense_units: int = 128,\n",
    "                dropout_rate: float = 0.2) -> keras.Model:\n",
    "    \"\"\"\n",
    "    Define and return a Sequential model with:\n",
    "      - Embedding\n",
    "      - Two stacked bidirectional GRUs + layer norms\n",
    "      - A Dense block + Dropout\n",
    "      - TimeDistributed softmax output\n",
    "    \"\"\"\n",
    "    return keras.models.Sequential([\n",
    "        Embedding(input_dim=max_ids, output_dim=embedding_dim),\n",
    "        Bidirectional(GRU(gru_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)),\n",
    "        LayerNormalization(),\n",
    "        Bidirectional(GRU(gru_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)),\n",
    "        LayerNormalization(),\n",
    "        Dense(dense_units, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        TimeDistributed(Dense(max_ids, activation=\"softmax\"))\n",
    "    ])\n",
    "\n",
    "\n",
    "def compile_model(model: keras.Model,\n",
    "                  initial_lr: float = 5e-4,\n",
    "                  decay_steps: int = 5000,\n",
    "                  decay_rate: float = 0.9,\n",
    "                  staircase: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Attach an Adam optimizer with an exponential decay LR schedule,\n",
    "    compile with sparse_categorical_crossentropy + accuracy.\n",
    "    \"\"\"\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=initial_lr,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=decay_rate,\n",
    "        staircase=staircase\n",
    "    )\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "def train_model(model: keras.Model,\n",
    "                dataset,\n",
    "                epochs: int = 10,\n",
    "                validation_data=None,\n",
    "                checkpoint_path: str = \"best_model.keras\",\n",
    "                patience: int = 5,\n",
    "                verbose: int = 1) -> keras.callbacks.History:\n",
    "    \"\"\"\n",
    "    Train given model on `dataset`.\n",
    "      - Uses EarlyStopping on val_loss (if validation_data provided).\n",
    "      - Saves best model to `checkpoint_path`.\n",
    "      - Returns the training History object.\n",
    "    \"\"\"\n",
    "    callbacks = []\n",
    "    if validation_data is not None:\n",
    "        callbacks += [\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_path,\n",
    "                save_best_only=True,\n",
    "                monitor=\"val_loss\",\n",
    "                verbose=verbose\n",
    "            ),\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=patience,\n",
    "                restore_best_weights=True,\n",
    "                verbose=verbose\n",
    "            )\n",
    "        ]\n",
    "    history = model.fit(\n",
    "        dataset,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_data,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    return history\n",
    "def evaluate_model(model: keras.Model,\n",
    "                   dataset,\n",
    "                   verbose: int = 1) -> dict:\n",
    "   \n",
    "    # Run evaluation\n",
    "    results = model.evaluate(dataset, verbose=verbose)\n",
    "    names = model.metrics_names  # e.g. ['loss', 'accuracy']\n",
    "    metrics = dict(zip(names, results))\n",
    "\n",
    "    # Print them nicely\n",
    "    print(\"\\nEvaluation results:\")\n",
    "    for name, value in metrics.items():\n",
    "        print(f\"  {name.capitalize():<10}: {value:.4f}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def save_model(model: keras.Model, filepath: str) -> None:\n",
    "    \"\"\"Save the entire model to the given filepath.\"\"\"\n",
    "    dirname = os.path.dirname(filepath)\n",
    "    if dirname and not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    #This is the main command to save the model\n",
    "    model.save(filepath)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "\n",
    "def load_model(filepath: str) -> keras.Model:\n",
    "    \"\"\"Load and return a model from disk.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"No model found at: {filepath}\")\n",
    "    print(f\"Loading model from {filepath}\")\n",
    "    #This is the command to load the model\n",
    "    return keras.models.load_model(filepath)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "085c9ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model...\n",
      "Loading model from best_shakespeare_model.keras\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists(\"best_shakespeare_model.keras\")):  # Check if the model exists\n",
    "    print(\"Loading existing model...\")\n",
    "    model = load_model(\"best_shakespeare_model.keras\")  # Load the best model if it exists\n",
    "else:\n",
    "    print(\"Building new model...\")\n",
    "    model = build_model(max_ids=max_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcda088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_model(model, initial_lr=5e-4, decay_steps=5000, decay_rate=0.9, staircase=True)\n",
    "history = train_model(model, dataset=dataset, epochs=0, validation_data=None, checkpoint_path=\"best_shakespeare_model.keras\", patience=5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0c18b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 358ms/step - accuracy: 0.9967 - loss: 0.0108\n",
      "\n",
      "Evaluation results:\n",
      "  Loss      : 0.0109\n",
      "  Compile_metrics: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.010876116342842579, 'compile_metrics': 0.9967038631439209}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_eval_dataset = dataset.take(100)\n",
    "evaluate_model(model, small_eval_dataset, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e38af",
   "metadata": {},
   "source": [
    "now lets just satrt to run the model for basic nlp tasks.Ths is how basic NLPS work they just they start predicting the next word formt eh given words that have been given to them.Also there are again used as input for further language preocessing and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bb9124f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts))-1\n",
    "    return tf.one_hot(X,max_ids)\n",
    "def predict_next_char(model: keras.Model, tokenizer, seed_text: str, max_sequence_len: int) -> str:\n",
    "    padded_input = keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([seed_text.lower()]), maxlen=max_sequence_len, padding='pre')\n",
    "    predicted_char_idx = np.argmax(model.predict(padded_input, verbose=0)[0, -1])\n",
    "    return tokenizer.index_word.get(predicted_char_idx, \"\")\n",
    "# Example usage\n",
    "seed_text = \"Hi\"\n",
    "predict_next_char(model, tokenizer, seed_text, n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
