{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6ac3c9-518c-4fcc-938c-6db31bbd055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411b4c31-f9fd-4eaa-9afa-8ea5b4f1358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23048a5b-a8e5-49ab-afe5-68a716d7af89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 10:40:15.868536: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Define basic parameters\n",
    "vocab_size = 10000       # use actual vocab size\n",
    "embed_size = 256         # dimension of embeddings\n",
    "max_seq_len = 100        # max input sequence length (can be dynamic if masked)\n",
    "\n",
    "embeddings = keras.layers.Embedding(vocab_size, embed_size)\n",
    "encoder_embeddings = embeddings(encoder_inputs)\n",
    "decoder_embeddings = embeddings(decoder_inputs)\n",
    "encoder = keras.layers.LSTM(512, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8959284e-20dd-414c-af48-3f794ae3be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Shared embedding layer\n",
    "embedding_layer = keras.layers.Embedding(vocab_size, embed_size, name=\"shared_embedding\")\n",
    "\n",
    "encoder_embeddings = embedding_layer(encoder_inputs)  # (batch, time, embed)\n",
    "decoder_embeddings = embedding_layer(decoder_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ceaab36-a27a-416a-b145-5b579628c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Encoder — LSTM returns final hidden and cell state\n",
    "encoder_lstm = keras.layers.LSTM(512, return_state=True, name=\"encoder_lstm\")\n",
    "_, state_h, state_c = encoder_lstm(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26fd2274-1e5e-45a0-9d73-1fcfc73e846b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling BasicDecoder.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'basic_decoder' (of type BasicDecoder). Either the `BasicDecoder.call()` method is incorrect, or you need to implement the `BasicDecoder.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\n'NoneType' object is not subscriptable\u001b[0m\n\nArguments received by BasicDecoder.call():\n  • args=('<KerasTensor shape=(None, None, 256), dtype=float32, sparse=False, ragged=False, name=keras_tensor_9>',)\n  • kwargs={'initial_state': ['<KerasTensor shape=(None, 512), dtype=float32, sparse=False, ragged=False, name=keras_tensor_11>', '<KerasTensor shape=(None, 512), dtype=float32, sparse=False, ragged=False, name=keras_tensor_12>'], 'sequence_length': '<KerasTensor shape=(None,), dtype=int32, sparse=False, ragged=False, name=keras_tensor_2>'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      7\u001b[39m decoder = tfa.seq2seq.BasicDecoder(\n\u001b[32m      8\u001b[39m     cell=decoder_cell,\n\u001b[32m      9\u001b[39m     sampler=sampler,\n\u001b[32m     10\u001b[39m     output_layer=output_layer,\n\u001b[32m     11\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mbasic_decoder\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# decoder_outputs.rnn_output shape: (batch, time, vocab_size)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m decoder_outputs, _, _ = \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43msequence_lengths\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m Y_proba = tf.nn.softmax(decoder_outputs.rnn_output, axis=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python_datascience/aiprac2/NLPs/myenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python_datascience/aiprac2/NLPs/myenv/lib/python3.12/site-packages/tensorflow_addons/seq2seq/decoder.py:162\u001b[39m, in \u001b[36mBaseDecoder.call\u001b[39m\u001b[34m(self, inputs, initial_state, training, **kwargs)\u001b[39m\n\u001b[32m    160\u001b[39m init_kwargs = kwargs\n\u001b[32m    161\u001b[39m init_kwargs[\u001b[33m\"\u001b[39m\u001b[33minitial_state\u001b[39m\u001b[33m\"\u001b[39m] = initial_state\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdynamic_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_time_major\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput_time_major\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimpute_finished\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimpute_finished\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_init_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_init_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python_datascience/aiprac2/NLPs/myenv/lib/python3.12/site-packages/typeguard/__init__.py:1033\u001b[39m, in \u001b[36mtypechecked.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1031\u001b[39m memo = _CallMemo(python_func, _localns, args=args, kwargs=kwargs)\n\u001b[32m   1032\u001b[39m check_argument_types(memo)\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m retval = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1035\u001b[39m     check_return_type(retval, memo)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python_datascience/aiprac2/NLPs/myenv/lib/python3.12/site-packages/tensorflow_addons/seq2seq/decoder.py:363\u001b[39m, in \u001b[36mdynamic_decode\u001b[39m\u001b[34m(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, training, scope, enable_tflite_convertible, **kwargs)\u001b[39m\n\u001b[32m    350\u001b[39m     zero_outputs = tf.nest.map_structure(\n\u001b[32m    351\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m shape, dtype: tf.reshape(\n\u001b[32m    352\u001b[39m             tf.zeros(_prepend_batch(decoder.batch_size, shape), dtype=dtype),\n\u001b[32m   (...)\u001b[39m\u001b[32m    356\u001b[39m         decoder.output_dtype,\n\u001b[32m    357\u001b[39m     )\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    359\u001b[39m     zero_outputs = tf.nest.map_structure(\n\u001b[32m    360\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m shape, dtype: tf.zeros(\n\u001b[32m    361\u001b[39m             _prepend_batch(decoder.batch_size, shape), dtype=dtype\n\u001b[32m    362\u001b[39m         ),\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         \u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_size\u001b[49m,\n\u001b[32m    364\u001b[39m         decoder.output_dtype,\n\u001b[32m    365\u001b[39m     )\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maximum_iterations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    368\u001b[39m     initial_finished = tf.logical_or(initial_finished, \u001b[32m0\u001b[39m >= maximum_iterations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python_datascience/aiprac2/NLPs/myenv/lib/python3.12/site-packages/tensorflow_addons/seq2seq/basic_decoder.py:157\u001b[39m, in \u001b[36mBasicDecoder.output_size\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moutput_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# Return the cell output and the id\u001b[39;00m\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BasicDecoderOutput(\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         rnn_output=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rnn_output_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, sample_id=\u001b[38;5;28mself\u001b[39m.sampler.sample_ids_shape\n\u001b[32m    158\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python_datascience/aiprac2/NLPs/myenv/lib/python3.12/site-packages/tensorflow_addons/seq2seq/basic_decoder.py:151\u001b[39m, in \u001b[36mBasicDecoder._rnn_output_size\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    145\u001b[39m output_shape_with_unknown_batch = tf.nest.map_structure(\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m s: tf.TensorShape([\u001b[38;5;28;01mNone\u001b[39;00m]).concatenate(s), size\n\u001b[32m    147\u001b[39m )\n\u001b[32m    148\u001b[39m layer_output_shape = \u001b[38;5;28mself\u001b[39m.output_layer.compute_output_shape(\n\u001b[32m    149\u001b[39m     output_shape_with_unknown_batch\n\u001b[32m    150\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_output_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python_datascience/aiprac2/NLPs/myenv/lib/python3.12/site-packages/tensorflow_addons/seq2seq/basic_decoder.py:151\u001b[39m, in \u001b[36mBasicDecoder._rnn_output_size.<locals>.<lambda>\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    145\u001b[39m output_shape_with_unknown_batch = tf.nest.map_structure(\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m s: tf.TensorShape([\u001b[38;5;28;01mNone\u001b[39;00m]).concatenate(s), size\n\u001b[32m    147\u001b[39m )\n\u001b[32m    148\u001b[39m layer_output_shape = \u001b[38;5;28mself\u001b[39m.output_layer.compute_output_shape(\n\u001b[32m    149\u001b[39m     output_shape_with_unknown_batch\n\u001b[32m    150\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tf.nest.map_structure(\u001b[38;5;28;01mlambda\u001b[39;00m s: \u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m, layer_output_shape)\n",
      "\u001b[31mTypeError\u001b[39m: Exception encountered when calling BasicDecoder.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'basic_decoder' (of type BasicDecoder). Either the `BasicDecoder.call()` method is incorrect, or you need to implement the `BasicDecoder.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\n'NoneType' object is not subscriptable\u001b[0m\n\nArguments received by BasicDecoder.call():\n  • args=('<KerasTensor shape=(None, None, 256), dtype=float32, sparse=False, ragged=False, name=keras_tensor_9>',)\n  • kwargs={'initial_state': ['<KerasTensor shape=(None, 512), dtype=float32, sparse=False, ragged=False, name=keras_tensor_11>', '<KerasTensor shape=(None, 512), dtype=float32, sparse=False, ragged=False, name=keras_tensor_12>'], 'sequence_length': '<KerasTensor shape=(None,), dtype=int32, sparse=False, ragged=False, name=keras_tensor_2>'}"
     ]
    }
   ],
   "source": [
    "# STEP 6: Define decoder with TrainingSampler\n",
    "decoder_cell = keras.layers.LSTMCell(512, name=\"decoder_lstm_cell\")\n",
    "output_layer = keras.layers.Dense(vocab_size, name=\"output_projection\")\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "decoder = tfa.seq2seq.BasicDecoder(\n",
    "    cell=decoder_cell,\n",
    "    sampler=sampler,\n",
    "    output_layer=output_layer,\n",
    "    name=\"basic_decoder\"\n",
    ")\n",
    "\n",
    "# decoder_outputs.rnn_output shape: (batch, time, vocab_size)\n",
    "decoder_outputs, _, _ = decoder(\n",
    "    decoder_embeddings,\n",
    "    initial_state=encoder_state,\n",
    "    sequence_length=sequence_lengths\n",
    ")\n",
    "\n",
    "Y_proba = tf.nn.softmax(decoder_outputs.rnn_output, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a386422-d63d-49ca-8c6f-25790fdea070",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_proba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# STEP 7: Final model\u001b[39;00m\n\u001b[32m      2\u001b[39m model = keras.Model(\n\u001b[32m      3\u001b[39m     inputs=[encoder_inputs, decoder_inputs, sequence_lengths],\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     outputs=[\u001b[43mY_proba\u001b[49m],\n\u001b[32m      5\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mSeq2Seq_Training_Model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m model.summary()\n",
      "\u001b[31mNameError\u001b[39m: name 'Y_proba' is not defined"
     ]
    }
   ],
   "source": [
    "# STEP 7: Final model\n",
    "model = keras.Model(\n",
    "    inputs=[encoder_inputs, decoder_inputs, sequence_lengths],\n",
    "    outputs=[Y_proba],\n",
    "    name=\"Seq2Seq_Training_Model\"\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf4122-57c8-4782-a022-fc5b2e1e8776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
