{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8b7e40b-b602-430a-9dfa-a8f88170df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GRU, Dense, Embedding, LayerNormalization, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceef9d65-4315-4728-9c27-171c621d46d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "# Download Shakespeare text\n",
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath, 'r', encoding='utf-8') as f:\n",
    "    text = f.read().lower()  # Lowercase to reduce vocabulary size\n",
    "\n",
    "# Inspect the first 100 characters\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "878a7f0e-8fa5-4362-820e-a25029014d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 39\n",
      "Unique characters: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# Create vocabulary\n",
    "chars = sorted(set(text))\n",
    "max_id = len(chars)\n",
    "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
    "idx_to_char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "print(f\"Vocabulary size: {max_id}\")\n",
    "print(f\"Unique characters: {chars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "636a836e-f728-4b4a-914c-b7107be4b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert text to integers\n",
    "text_as_int = np.array([char_to_idx[c] for c in text])\n",
    "\n",
    "# Create a TensorFlow Dataset\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ac9bb91-582f-4450-89f8-c5127097b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences of length 100\n",
    "seq_length = 100\n",
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "# Create input-target pairs\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "025f5ae3-314c-4a79-9b3d-4b720e436493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle, batch, and prefetch\n",
    "dataset = dataset.shuffle(10000).batch(64, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e95cbc01-dc90-432a-97a5-1b71b8ea2a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.13/site-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU, Dense, Embedding, LayerNormalization, TimeDistributed\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(max_id, 64, input_shape=[None]),\n",
    "    GRU(128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1),\n",
    "    LayerNormalization(),\n",
    "    GRU(128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1),\n",
    "    LayerNormalization(),\n",
    "    TimeDistributed(Dense(max_id, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile with Adam\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de3a155f-9caf-4a0f-8b1a-ce016c89443e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 143ms/step - accuracy: 0.2624 - loss: 2.6717 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 148ms/step - accuracy: 0.3961 - loss: 2.0363 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 146ms/step - accuracy: 0.4367 - loss: 1.8845 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 138ms/step - accuracy: 0.4617 - loss: 1.7918 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 144ms/step - accuracy: 0.4767 - loss: 1.7319 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 142ms/step - accuracy: 0.4888 - loss: 1.6874 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 140ms/step - accuracy: 0.4976 - loss: 1.6554 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 141ms/step - accuracy: 0.5040 - loss: 1.6291 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 130ms/step - accuracy: 0.5100 - loss: 1.6067 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 132ms/step - accuracy: 0.5126 - loss: 1.5938 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 136ms/step - accuracy: 0.5173 - loss: 1.5770 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 142ms/step - accuracy: 0.5204 - loss: 1.5637 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 144ms/step - accuracy: 0.5240 - loss: 1.5497 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 207ms/step - accuracy: 0.5250 - loss: 1.5448 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.5284 - loss: 1.5321 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 0.5299 - loss: 1.5238 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.5315 - loss: 1.5185 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.5343 - loss: 1.5087 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 99ms/step - accuracy: 0.5344 - loss: 1.5071 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 99ms/step - accuracy: 0.5352 - loss: 1.5022 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Define callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(dataset, epochs=50, callbacks=[reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15cb698e-432f-4cbd-bcb6-12912de86e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, char_to_idx, idx_to_char, seed_text, length=200, temperature=0.7):\n",
    "    text = seed_text.lower()\n",
    "    generated = []\n",
    "    for _ in range(length):\n",
    "        input_ids = [char_to_idx.get(c, 0) for c in text[-seq_length:]]\n",
    "        input_ids = tf.expand_dims(input_ids, 0)\n",
    "        preds = model(input_ids, training=False)[0, -1, :]\n",
    "        preds = tf.math.log(preds) / temperature\n",
    "        next_idx = tf.random.categorical(preds[tf.newaxis, :], num_samples=1)\n",
    "        next_idx = int(next_idx[0, 0])\n",
    "        generated.append(idx_to_char[next_idx])\n",
    "        text += idx_to_char[next_idx]\n",
    "    return seed_text + ''.join(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "894f1d21-5403-49d2-863e-6bedd9f8eed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be or not to be hath can do near part.\n",
      "\n",
      "plance:\n",
      "i should be a virtuous end them to the soldier,\n",
      "when i love the regroop. the proud my how the letter:\n",
      "ay, i come that the sun,\n",
      "and thy scarred the serves, with the wor\n"
     ]
    }
   ],
   "source": [
    "seed = \"To be or not to be\"\n",
    "generated_text = generate_text(model, char_to_idx, idx_to_char, seed)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2fe27cf-7bdf-451c-9753-2ba2bd4fb65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a Student to the care\\nand wail have with the lady with all be fight:\\nand they shall be the present of a man; it is soul,\\nwhat, i were a day my volscies of your incress they revel that you do you the myself\\ntha'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, char_to_idx, idx_to_char, \"I am a Student\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98fa2af4-6476-4a9c-9211-726aade93be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# after training finishes\n",
    "model.save(\"shakespeare_generator_lite.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fd162d-d4c8-42d0-9366-99d5a0c2e493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
