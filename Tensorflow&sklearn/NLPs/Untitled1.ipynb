{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683467cc-708f-4872-9164-b15c8f56990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "data_path = tf.keras.utils.get_file(\"shakespeare.txt\", origin=url)\n",
    "\n",
    "# Read once, do light cleanup outside the pipeline\n",
    "raw = tf.io.read_file(data_path).numpy().decode(\"utf-8\")\n",
    "text = raw.lower()\n",
    "text = re.sub(r\"\\[.*?\\]\", \"\", text)      # drop stage directions\n",
    "text = re.sub(r\"\\s+\", \" \", text).strip() # collapse whitespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f3de285-269f-4a61-8146-2f76d55588ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "keys = tf.constant(chars)\n",
    "vals = tf.range(vocab_size, dtype=tf.int64)\n",
    "\n",
    "table = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(keys, vals),\n",
    "    default_value=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e23621-31b0-468f-886b-1a8928bc3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len, batch_size, buffer = 100, 64, 10_000\n",
    "\n",
    "ds = (\n",
    "    tf.data.Dataset\n",
    "      .from_tensor_slices(tf.strings.unicode_split(text, \"UTF-8\"))\n",
    "      .map(table.lookup, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "      # sliding window of length+1, 1‑step shift\n",
    "      .window(seq_len+1, shift=1, drop_remainder=True)\n",
    "      .flat_map(lambda w: w.batch(seq_len+1))\n",
    "      .map(lambda w: (w[:-1], w[1:]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "      .shuffle(buffer)\n",
    "      .batch(batch_size, drop_remainder=True)\n",
    "      .cache()                    # keep one epoch in RAM\n",
    "      .repeat()                   # infinite for model.fit\n",
    "      .prefetch(tf.data.AUTOTUNE) # overlap preprocessing & training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0118a674-9244-4ba7-83d3-525b3f602c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 08:21:40.089784: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-07 08:21:40.374408: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loading saved model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">296,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,766</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m4,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m296,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m)       │         \u001b[38;5;34m9,766\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">311,080</span> (1.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m311,080\u001b[0m (1.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">311,078</span> (1.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m311,078\u001b[0m (1.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "\n",
    "model_path = \"shakespeare_model.h5\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"✅ Loading saved model...\")\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "else:\n",
    "    print(\"🔧 Building new model...\")\n",
    "    \n",
    "    embed_dim = 128\n",
    "    rnn_units = 256\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=[None]),\n",
    "        keras.layers.Embedding(vocab_size, embed_dim),\n",
    "        keras.layers.GRU(rnn_units, return_sequences=True, dropout=0.2),\n",
    "        keras.layers.TimeDistributed(\n",
    "            keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e52d529-cb7b-4b4a-b597-d1b454dfdc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17313/17313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3156s\u001b[0m 182ms/step - accuracy: 0.7227 - loss: 0.9355 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "steps = (len(text) - seq_len) // batch_size\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2),\n",
    "    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    keras.callbacks.ModelCheckpoint(\"best.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    ds,\n",
    "    epochs=1,\n",
    "    steps_per_epoch=steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c79daf80-6b5b-47e9-9507-2e1e9efd28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild vocab if not done already\n",
    "vocab = sorted(set(text))\n",
    "id2char = np.array(vocab)  # index → character mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bde7bcc-5258-44a5-a998-5fe0545fbd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(seed=\"romeo:\", length=300, temp=0.8):\n",
    "    chars = list(seed.lower())\n",
    "    ids = table.lookup(tf.constant(chars)).numpy().tolist()\n",
    "    out = chars.copy()\n",
    "\n",
    "    for _ in range(length):\n",
    "        x = tf.expand_dims(ids[-seq_len:], 0)\n",
    "        probs = model.predict(x, verbose=0)[0, -1]\n",
    "        nxt = sample(probs, temp)\n",
    "        ids.append(nxt)\n",
    "        out.append(id2char[nxt])  # fixed line\n",
    "\n",
    "    return \"\".join(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be27526f-a5e7-4e9a-a86b-0f0a08ac1a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juliet: hark! would i had never married my daughter there! gonzalo: all things in common nature should produce of surpet it underge and heart. antonio: the fire. petruchio: and then to be reputal more, and she didons a shorsed with good the subjects? antonio: none, man; all idle, whom i prithee, peace, my \n",
      "juliet: do not thy stowam, all, sleep. gonzalo: when i wores are in either's poxting into my this is at your sirst gonzalo: by 'longing singerity, would it not laft mine, and mille! antonio: if but are two oft? ariel: she saw, my father's laft noor on a his merrive to comfort thee: for, come, thou shouldst\n",
      "juliet: houth. ariel: so shalt the dind he. spoken, do commits you speak? gonzalo: what is't contitait:. for we twints, is not this blesserfy. slave, should pardon, my remembant comfort like conscien. sebastian: as siching me thy beheod this to sleep, and such perses! o, i flot the most, in disp; o hont, w\n"
     ]
    }
   ],
   "source": [
    "print(generate(\"juliet:\", temp=0.5))  # more predictable\n",
    "print(generate(\"juliet:\", temp=1.0))  # balanced\n",
    "print(generate(\"juliet:\", temp=1.2))  # more creative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38066467-c636-4e86-ad03-c661e55c1865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"shakespeare_model.h5\")  # HDF5 format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb715e0-1885-4c3e-ae7d-1e3cffd316f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
